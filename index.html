<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="AI for Key Frame Extraction to Digitize My Pet">
  <meta property="og:title" content="Pawframe - Unpeil"/>
  <meta property="og:description" content="AI for Key Frame Extraction to Digitize My Pet"/>
  <meta property="og:url" content="unpeil.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/unveil-your-pet.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Pawframe - Unpeil">
  <meta name="twitter:description" content="AI for Key Frame Extraction to Digitize My Pet">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/unveil-your-pet.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Unpeil, Pawframe, AI, Image Extraction">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Pawframe</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AI for Key Fram Extraction to Digitize My Pet, Pawframe</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Seungwoo Seo</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Sangmin Kim</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Hyundong Kim</a><sup>*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Unpeil<br>CES 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
      <!-- Your video here -->
      <!-- <source src="static/videos/banner_video.mp4"
      type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
      Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Unpeil introduces <b>Pawframe</b>, a groundbreaking technology that exports key frames based on pet facial expressions to extract high-quality labeled image data, providing an image dataset ideally suited for AI processing.
          </p>
        </div>
        <h2 class="title is-4">Background</h2>
        <div class="content has-text-justified">
          <p>
            In the current era of generative AI, where creative outputs are booming, the development of Large Multi-Modal models—capable of processing not just text but also images, videos, and sounds as inputs—has become increasingly active. Unlike traditional models like GPT-3 and Stable Diffusion, which rely solely on text inputs, these new models utilize diverse data formats.
          </p>
          <p>
            Most multi-modal models that take videos as input currently adopt a sequential screenshot method, capturing images at predetermined intervals without considering the content of the video. In contrast, Unpeil's <b>Pawframe</b> technology codes the threshold points of pet facial expressions in the same environment, allowing it to select and extract qualitatively superior images as key frames.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Architecture</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/architecture1.png" alt="Pawframe Architecture"/>
        <h2 class="subtitle has-text-centered">
          Overall architecture of Pawframe.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/architecture2.png" alt="Pawframe Architecture"/>
        <h2 class="subtitle has-text-centered">
          Overall architecture of Pawframe.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Process</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/architecture3.png" alt="Pawframe Architecture"/>
        <h2 class="subtitle has-text-centered">
          Process of key frame extraction.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/architecture4.png" alt="Pawframe Architecture"/>
        <h2 class="subtitle has-text-centered">
          Process of key frame extraction.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Product</h2>
        <h2 class="title is-5">Engineering</h2>
        <div class="content has-text-justified">
          <p>
            <b>Pawframe</b> transforms pet videos into a structured image set through a three-stage process:
          </p>
          <ol>
            <li>
              <b>Segmentation</b>: In the first stage, the system detects and segments objects and motions within the video. This step ensures precise identification of relevant elements, focusing specifically on the pet's movements and expressions.
            </li>
            <li>
              <b>FACS Labeling</b>: After recognizing the pet's face, Pawframe applies a Facial Action Coding System (FACS) developed by Unpeil. This system, built on the analysis of over 100,000 data points, is tailored to each different pet species. It labels facial expression thresholds with corresponding text annotations, and these labels are saved along with the captured images.
            </li>
            <li>
              <b>Database Storage</b>: The labeled image set is then stored in a database, similar to a video summarization. This process creates a concise and organized collection of keyframes.
            </li>
          </ol>
          <p>
            The summarized keyframes can be used as-is, or they can be further utilized in secondary creative processes such as AI modeling, machine learning, and the creation of <i>Metadog</i>. This approach allows for the efficient generation of additional AI processing data, enabling rapid learning and storage with a lightweight dataset. By limiting the number of redundant data points, Pawframe also helps prevent AI overfitting, ensuring robust and reliable model training.
          </p>
        </div>
        <h2 class="title is-5">Design</h2>
        <div class="content has-text-justified">
          <p>
            Pawframe is offered as an API, optimized to allow AI to understand and learn from everyday pet videos captured on an iPhone. It enables quick and lightweight customization of objects, making it easy to integrate with other software.
          </p>
          <p>
            Through Pawframe, consumers can experience a world where their pets are digitally recreated, most notably in an online memorial park. We envision a future where your pet’s digital presence is indistinguishable from reality. Unlike pre-set motion graphics that merely apply a pet’s skin, Pawframe’s labeling data and advanced AI learning enable your digital pet to interact with you, follow physical engines, and provide comfort without any sense of detachment. This becomes even more effective when combined with ambience and physical engines in XR devices.
          </p>
          <p>
            Customers input videos without any preprocessing and receive high-quality, video-summarized image sets ideal for generative AI processing. These summarized videos not only convey the overall content but also create significant added value in AI-generated outputs such as images, videos, MetaDog.
          </p>
          <p>
            Unpeil uses Pawframe to develop an online memorial service for XR-Device. Pet owners can use it as content while their pets are with them, and as a space for comfort after their pets have crossed the rainbow bridge.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Innovation</h2>
        <div class="content has-text-justified">
          <p>
            Unpeil addresses the social challenges faced by pets, a technologically underserved group through innovative solutions.
          </p>
          <ul>
            <li>
              <b>Superior Technology</b>: Pawframe leverages a species-specific pet FACS, developed using over 100,000 data points, to automate preprocessing for AI training. This advanced system enables the extraction of high-quality, labeled datasets from video inputs alone, streamlining the process of creating AI-ready data with minimal human intervention.
            </li>
            <li>
              <b>Cultural Symbiosis with Pets</b>: As the demand for pet welfare grows, Pawframe addresses the need for fine-tuning technology specifically for pets. In many countries, pets do not have portrait or intellectual property rights, making it easier to collect and utilize data for AI training. Moreover, AI models refined for pets can be adapted back to human applications, fostering a deeper connection between human and pet technology.
            </li>
            <li>
              <b>Healing from Loss</b>: Pawframe offers a groundbreaking approach to Pet Loss Therapy, particularly in high-GDP countries where pets are considered family members. By digitally recreating pets, Pawframe helps owners cope with grief, providing comfort and therapeutic effects through interactive, personalized experiences. The technology not only evokes nostalgia but also simulates "what if" scenarios, offering profound emotional support to those mourning the loss of a beloved pet.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          <p>
            Pawframe is an innovative AI technology designed to extract high-quality key frames from pet videos. Leveraging Facial Action Coding System(FACS) specifically trained on over 100,000 data points, Pawframe accurately identifies critical expression thresholds in pets, extracting the most impactful frames. Unlike traditional models that rely on sequential screenshots, Pawframe focuses on the qualitative extraction of images, optimizing them for AI processing and storage. 
          </p>
          <p>This technology empowers users—both pet owners and service providers—to obtain a refined, video-summarized image set without extra preprocessing, enhancing AI-generated content creation across images, videos, and other multi-modal applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
    <div class="colums has-text-centered">
      <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Funpeil.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=github.svg&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
